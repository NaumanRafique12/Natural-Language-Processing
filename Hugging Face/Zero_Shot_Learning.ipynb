{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Agenda**:\n",
        "1. What is Zero-Shot Learning or Zero-shot classification?\n",
        "2. How zero shot learning models work?\n",
        "3. Zero-shot classification using HuggingFace Transformers"
      ],
      "metadata": {
        "id": "q6gb33mZekdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How does Zero-Shot Learning work?** <br>\n",
        "Zero-shot learning is when we are testing a model on a task for which it hasn't been trained.\n",
        "\n",
        "In **Zero-shot classification** we are asking the model to do classification for labels which model hasn't seen during the model."
      ],
      "metadata": {
        "id": "mPdrPzcJderf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the popular methods for zero-shot learning is **Natural Language Inference** (NLI).<br>\n",
        "\n",
        "*Natural language inference* is the task of determining whether a “hypothesis” is true (entailment), false (contradiction), or undetermined (neutral) given a “premise”."
      ],
      "metadata": {
        "id": "syhhq8pJduWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the NLI method we can propose a sentence to be classified as a **Premise** and can construct a **hypothesis** for each classification label?\n",
        "\n",
        "E.g Let's say we have the sentence “**one day I will see the world**” and we would like to classify whether this sentence is about\n",
        "\n",
        "1. travel,\n",
        "\n",
        "2. cooking,\n",
        "\n",
        "3. dancing\n",
        "\n",
        "Now for all three classification labels, we can have three hypothesis\n",
        "\n",
        "Hypothesis 1: This text is about travel\n",
        "\n",
        "Hypothesis 2: This text is about cooking\n",
        "\n",
        "Hypothesis 3: This text is about dancing"
      ],
      "metadata": {
        "id": "AwcvchpVeGC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "z9eUCjJ8e3A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
      ],
      "metadata": {
        "id": "Sk5cWk-zlBjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_to_classify = \"one day I will see the world\"\n",
        "candidate_labels = ['travel', 'cooking', 'dancing']\n",
        "\n",
        "classifier(sequence_to_classify, candidate_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8FsMywpecFP",
        "outputId": "802e8170-d5ef-4b93-efca-359371c608a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'one day I will see the world',\n",
              " 'labels': ['travel', 'dancing', 'cooking'],\n",
              " 'scores': [0.9938651919364929, 0.0032737930305302143, 0.0028610294684767723]}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If more than one candidate label can be correct.**"
      ],
      "metadata": {
        "id": "3qfXHlTBfpxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_labels = ['travel', 'cooking', 'dancing', 'exploration']\n",
        "classifier(sequence_to_classify, candidate_labels, multi_label=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba9bICMOfmdQ",
        "outputId": "91f585eb-ed20-4f9d-85ef-4538111135c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'one day I will see the world',\n",
              " 'labels': ['travel', 'exploration', 'dancing', 'cooking'],\n",
              " 'scores': [0.994511067867279,\n",
              "  0.9383882880210876,\n",
              "  0.005706177558749914,\n",
              "  0.001819281023927033]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_to_classify = \"Donald Trump will be next president\"\n",
        "candidate_labels = ['science', 'politics', 'history']\n",
        "\n",
        "classifier(sequence_to_classify, candidate_labels)"
      ],
      "metadata": {
        "id": "0TB95KDSgQqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0cc6b6e-94ac-45b8-ba11-6cf4a706b370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'Donald Trump will be next president',\n",
              " 'labels': ['politics', 'history', 'science'],\n",
              " 'scores': [0.8404956459999084, 0.15547920763492584, 0.004025105386972427]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lFATPIUfknnZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}